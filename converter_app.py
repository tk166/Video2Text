import streamlit as st
import tempfile
import os
import sys
import torch
import time
import re

from audio_downloader import download_audio
from audio_converter import convert_to_wav
from funasr import AutoModel
from modelscope.hub.snapshot_download import snapshot_download
# ================= é…ç½®åŒº =================
# ä½ ç”¨åˆ°çš„ä¸‰ä¸ªæ¨¡å‹ ID å’Œç‰ˆæœ¬
MODEL_CONFIG = {
    "asr":  {"id": "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch", "ver": "v2.0.4"},
    "vad":  {"id": "iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",  "ver": "v2.0.4"},
    "punc": {"id": "iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch", "ver": "v2.0.4"},
}
# ================= é¢„ä¸‹è½½/æ£€æŸ¥ =================
@st.cache_data(show_spinner="æ­£åœ¨æ£€æŸ¥æœ¬åœ°æ¨¡å‹å®Œæ•´æ€§...")
def check_and_download_models():
    local_paths = {}
    print("----- å¼€å§‹æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ -----")
    try:
        # éå†ä¸‰ä¸ªæ¨¡å‹è¿›è¡Œæ£€æŸ¥
        for key, cfg in MODEL_CONFIG.items():
            # snapshot_download ä¼šè‡ªåŠ¨åˆ¤æ–­æœ¬åœ°ç¼“å­˜
            # å¦‚æœæœ¬åœ°å­˜åœ¨ï¼Œå®ƒä¸ä¼šå‘èµ·ç½‘ç»œè¯·æ±‚ï¼Œç›´æ¥è¿”å›è·¯å¾„ï¼Œé€Ÿåº¦æå¿«
            path = snapshot_download(model_id=cfg["id"], revision=cfg["ver"])
            local_paths[key] = path
            print(f"âœ… {key.upper()} æ¨¡å‹å°±ç»ª: {path}")
            
    except Exception as e:
        st.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ä»£ç†è®¾ç½®ï¼\næŠ¥é”™ä¿¡æ¯: {e}")
        st.stop() # åœæ­¢è¿è¡Œåç»­ä»£ç 
        
    return local_paths
# ================= åŠ è½½è¿›æ˜¾å­˜ï¼ˆé˜²å¡é¡¿æ ¸å¿ƒï¼‰ =================
@st.cache_resource(show_spinner="æ­£åœ¨åŠ è½½ç¥ç»ç½‘ç»œåˆ°æ˜¾å­˜ (åªåŠ è½½ä¸€æ¬¡)...")
def load_funasr_engine(device_select="cuda"):
    # 1. å…ˆç¡®ä¿æ–‡ä»¶éƒ½åœ¨ï¼ˆå¼•ç”¨ä¸Šé¢çš„å‡½æ•°ï¼‰
    paths = check_and_download_models()
    
    # 2. åˆå§‹åŒ–é‡å‹å¯¹è±¡
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– FunASR AutoModel...")
    model = AutoModel(
        model=paths["asr"],
        model_revision=MODEL_CONFIG["asr"]["ver"],
        
        vad_model=paths["vad"],
        vad_model_revision=MODEL_CONFIG["vad"]["ver"],
        
        punc_model=paths["punc"],
        punc_model_revision=MODEL_CONFIG["punc"]["ver"],
        
        device=device_select,
        num_workers=0, # é¿å… Streamlit å¤šçº¿ç¨‹æŠ¥é”™
    )
    print("ğŸ‰ æ¨¡å‹åˆå§‹åŒ–å®Œæ¯•ï¼")
    return model

if torch.cuda.is_available():
    device_select = "cuda"
# elif torch.backends.mps.is_available(): # å®æµ‹Apple M4çš„mpsç¨³å®šæ€§ä¸å¤ªè¡Œæ‰€ä»¥å…ˆæ³¨æ‰äº†
#     device_select = "mps"
else:
    device_select = "cpu"
model_instance = load_funasr_engine(device_select)

# --- æ ¸å¿ƒç»„ä»¶ï¼šæ—¥å¿—é‡å®šå‘ç±» ---
class StreamlitLogger:
    def __init__(self, log_container):
        self.log_container = log_container
        self.log_buffer = []
        self.original_stdout = sys.stdout
        self.original_stderr = sys.stderr
        
        # è¿™æ˜¯ä¸€ä¸ªèƒ½åŒ¹é…å‡ ä¹æ‰€æœ‰ ANSI è½¬ä¹‰åºåˆ—çš„æ­£åˆ™è¡¨è¾¾å¼
        # å®ƒèƒ½è¯†åˆ«é¢œè‰² (\x1b[34m) å’Œå…‰æ ‡ç§»åŠ¨ (\x1b[A) ç­‰
        self.ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')

    def write(self, message):
        # 1. ä»ç„¶è¾“å‡ºåˆ°åå°ç»ˆç«¯ (ä¿ç•™åŸå§‹å¸¦é¢œè‰²çš„æ ¼å¼ï¼Œæ–¹ä¾¿ä½ åœ¨ VSCode é‡Œçœ‹)
        self.original_stdout.write(message)
        
        # 2. æ¸…æ´—æ•°æ®ç»™ Streamlit æ˜¾ç¤º
        
        # ç¬¬ä¸€æ­¥ï¼šå»é™¤ ANSI é¢œè‰²å’Œæ§åˆ¶ç¬¦
        clean_message = self.ansi_escape.sub('', message)
        
        # ç¬¬äºŒæ­¥ï¼šå¤„ç†å›è½¦ç¬¦ \r
        # tqdm å–œæ¬¢ç”¨ \r å›åˆ°è¡Œé¦–è¦†ç›–è¿›åº¦ã€‚åœ¨ç½‘é¡µä¸Šæˆ‘ä»¬æŠŠå®ƒå˜æˆæ¢è¡Œ \nï¼Œ
        # è¿™æ ·è¿›åº¦æ¡å°±ä¼šå˜æˆç€‘å¸ƒæµï¼ˆä¸€è¡Œè¡Œæ˜¾ç¤ºï¼‰ï¼Œè€Œä¸æ˜¯æŒ¤åœ¨ä¸€èµ·ã€‚
        clean_message = clean_message.replace('\r', '\n')
        
        # ç¬¬ä¸‰æ­¥ï¼šå»é™¤ä¸€äº›å¯èƒ½æ®‹ç•™çš„ weird artifact (æ¯”å¦‚ [A å¦‚æœæ˜¯çº¯æ–‡æœ¬å½¢å¼å‡ºç°)
        # æœ‰æ—¶å€™ tqdm çš„ cursor up ä¼šç•™ä¸‹æ˜¾å¼çš„ [A
        clean_message = clean_message.replace('[A', '')

        if clean_message.strip():
            self.log_buffer.append(clean_message)
            
            # --- æ€§èƒ½ä¼˜åŒ– ---
            # åªä¿ç•™æœ€å 20 è¡Œæ—¥å¿—ï¼Œé¿å…ç½‘é¡µè¶Šæ¥è¶Šå¡
            if len(self.log_buffer) > 20:
                self.log_buffer = self.log_buffer[-20:]
            
            # æ˜¾ç¤ºæ¸…æ´—åçš„æ—¥å¿—
            self.log_container.code("".join(self.log_buffer), language="text")

    def flush(self):
        self.original_stdout.flush()
        self.original_stderr.flush()

def format_time(ms):
    """æ¯«ç§’è½¬SRTæ—¶é—´æ ¼å¼"""
    seconds = ms / 1000
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = int(seconds % 60)
    milliseconds = int(ms % 1000)
    return f"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}"

def generate_smart_srt(inference_result, min_length=10):
    """
    æ™ºèƒ½SRTç”Ÿæˆï¼š
    - ç¡¬æ ‡ç‚¹ (ã€‚ï¼Ÿï¼)ï¼šå¼ºåˆ¶æ¢è¡Œ
    - è½¯æ ‡ç‚¹ (ï¼Œã€)ï¼šåªæœ‰å½“å‰å¥é•¿åº¦è¶…è¿‡ min_length æ—¶æ‰æ¢è¡Œï¼Œå¦åˆ™åˆå¹¶
    """
    # 1. æå–æ•°æ®
    data = inference_result[0] if isinstance(inference_result, list) else inference_result
    text = data.get('text', '')
    ts_list = data.get('timestamp', [])
    
    # 2. å®šä¹‰æ ‡ç‚¹é›†åˆ
    # ç¡¬æ–­å¥ï¼šå¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·
    hard_break_chars = set("ã€‚ï¼Ÿï¼ï¼›ï¼š?!;:\n")
    # è½¯æ–­å¥ï¼šé€—å·ã€é¡¿å·ã€ç©ºæ ¼
    soft_break_chars = set("ï¼Œã€, ")
    
    srt_content = ""
    sentence_idx = 1
    ts_index = 0  # æ—¶é—´æˆ³æŒ‡é’ˆ
    
    # å½“å‰è¡Œçš„çŠ¶æ€ç¼“å­˜
    curr_text = ""
    curr_start = -1
    curr_end = 0
    
    for char in text:
        # --- A. å¤„ç†æ—¶é—´æˆ³ (å¦‚æœæ˜¯æœ‰æ•ˆæ–‡å­—) ---
        is_punctuation = char in hard_break_chars or char in soft_break_chars or char.isspace()
        
        if not is_punctuation:
            if ts_index < len(ts_list):
                start, end = ts_list[ts_index]
                # å¦‚æœæ˜¯å½“å‰è¡Œçš„ç¬¬ä¸€ä¸ªå­—
                if curr_start == -1:
                    curr_start = start
                # æ›´æ–°å½“å‰è¡Œçš„ç»“æŸæ—¶é—´
                curr_end = end
                ts_index += 1
        
        # --- B. æ‹¼æ¥å­—ç¬¦ ---
        curr_text += char
        
        # --- C. åˆ¤æ–­æ˜¯å¦æ–­å¥ ---
        should_flush = False
        
        # C1. ç¡¬æ–­å¥ï¼šé‡åˆ°å¥å·ï¼Œå¿…é¡»æ–­
        if char in hard_break_chars:
            should_flush = True
            
        # C2. è½¯æ–­å¥ï¼šé‡åˆ°é€—å·ï¼Œçœ‹å­—æ•°å¤Ÿä¸å¤Ÿ
        elif char in soft_break_chars:
            # åªæœ‰å½“å½“å‰å¥é•¿åº¦ >= è®¾å®šçš„æœ€å°é•¿åº¦æ—¶ï¼Œæ‰æ–­å¼€
            # å¦åˆ™å°±å¿½ç•¥è¿™ä¸ªé€—å·ï¼Œç»§ç»­å¾€åæ‹¼
            if len(curr_text) >= min_length:
                should_flush = True
        
        # --- D. æ‰§è¡Œæ–­å¥ ---
        if should_flush and curr_text.strip():
            # é˜²å¾¡ï¼šä¸‡ä¸€å…¨æ˜¯æ ‡ç‚¹æˆ–æ²¡æ—¶é—´æˆ³
            if curr_start == -1: 
                curr_start = curr_end # å…œåº•
                
            srt_content += f"{sentence_idx}\n"
            srt_content += f"{format_time(curr_start)} --> {format_time(curr_end)}\n"
            srt_content += f"{curr_text.strip()}\n\n" # stripå»æ‰é¦–å°¾ç©ºæ ¼
            
            sentence_idx += 1
            # é‡ç½®çŠ¶æ€
            curr_text = ""
            curr_start = -1
            
    # --- E. å¤„ç†æ®‹ç•™æ–‡æœ¬ ---
    if curr_text.strip():
        if curr_start == -1: curr_start = curr_end
        srt_content += f"{sentence_idx}\n"
        srt_content += f"{format_time(curr_start)} --> {format_time(curr_end)}\n"
        srt_content += f"{curr_text.strip()}\n\n"
        
    return srt_content

def update_srt_by_slider():
    """
    å½“æ»‘åŠ¨æ¡å˜åŒ–æ—¶è§¦å‘æ­¤å‡½æ•°ï¼š
    1. è·å–æ»‘åŠ¨æ¡çš„æ–°å€¼
    2. é‡æ–°è®¡ç®— SRT
    3. å¼ºåˆ¶è¦†ç›– text_area çš„çŠ¶æ€
    """
    # è·å–æ»‘åŠ¨æ¡å½“å‰çš„å€¼ (é€šè¿‡ key è·å–)
    min_len = st.session_state.srt_min_len_slider
    
    if "raw_res" in st.session_state:
        # é‡æ–°ç”Ÿæˆå†…å®¹
        new_content = generate_smart_srt(st.session_state.raw_res, min_length=min_len)
        
        # ğŸ’¥ å…³é”®ç‚¹ï¼šç›´æ¥ä¿®æ”¹ session_state ä¸­ text_area å¯¹åº”çš„ key
        # è¿™ä¼šå¼ºåˆ¶ Streamlit åœ¨ä¸‹ä¸€æ¬¡æ¸²æŸ“æ—¶ä½¿ç”¨è¿™ä¸ªæ–°å€¼
        st.session_state.editor_srt = new_content
        st.session_state.srt_result = new_content
# --- ä¸»ç¨‹åº ---

# åˆå§‹åŒ–session state
if "transcription_result" not in st.session_state:
    st.session_state.transcription_result = ""
if "srt_result" not in st.session_state:
    st.session_state.srt_result = ""
if "is_processed" not in st.session_state:
    st.session_state.is_processed = False

st.set_page_config(page_title="Video2Text", page_icon="ğŸ§")
st.title("ğŸ§ Video2Text - è¯­éŸ³è¯†åˆ«å·¥å…·")
st.markdown("å°†YouTube/Bilibiliè§†é¢‘è½¬æ¢ä¸ºæ–‡å­—")

# è§†é¢‘é“¾æ¥è¾“å…¥
video_url = st.text_input("è¯·è¾“å…¥YouTubeæˆ–Bilibiliè§†é¢‘é“¾æ¥:", placeholder="https://www.youtube.com/watch?v=...")

# å¤„ç†æŒ‰é’®
if st.button("å¼€å§‹å¤„ç†", type="primary") and video_url:
    st.session_state.is_processed = False
    
    # 1. åˆ›å»ºä¸€ä¸ªæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸï¼ˆé»˜è®¤æŠ˜å ï¼‰
    with st.expander("æŸ¥çœ‹è¯¦ç»†è¿è¡Œæ—¥å¿— (Terminal Output)", expanded=True):
        log_placeholder = st.empty()
    
    # å®ä¾‹åŒ–æˆ‘ä»¬çš„æ—¥å¿—æ•è·å™¨
    logger = StreamlitLogger(log_placeholder)
    
    # 2. ä½¿ç”¨ st.status åˆ›å»ºæ¼‚äº®çš„è¿›åº¦å®¹å™¨
    with st.status("æ­£åœ¨åˆå§‹åŒ–ä»»åŠ¡...", expanded=True) as status:
        
        # --- å…³é”®ï¼šå¼€å§‹åŠ«æŒ stdout ---
        sys.stdout = logger 
        sys.stderr = logger
        
        try:
            # æ­¥éª¤1: ä¸‹è½½éŸ³é¢‘
            status.update(label="æ­£åœ¨ä¸‹è½½éŸ³é¢‘ (yt-dlp)...", state="running")
            st.write("ğŸš€ å¼€å§‹è°ƒç”¨ä¸‹è½½å·¥å…·...") # è¿™è¡Œå­—ä¼šæ˜¾ç¤ºåœ¨æ—¥å¿—æ¡†é‡Œ
            
            # æ³¨æ„ï¼šå¦‚æœ download_audio å†…éƒ¨ä½¿ç”¨äº† printï¼Œä¼šè¢«æ•è·ã€‚
            # å¦‚æœå®ƒä½¿ç”¨ subprocess ç›´æ¥è¾“å‡ºåˆ°ç³»ç»Ÿç»ˆç«¯ï¼Œå¯èƒ½æ— æ³•è¢«æ•è·ï¼ˆè§ä¸‹æ–¹è¯´æ˜ï¼‰ã€‚
            audio_file = download_audio(video_url)
            st.write(f"âœ… ä¸‹è½½å®Œæˆ: {os.path.basename(audio_file)}")
            
            # æ­¥éª¤2: è½¬æ¢éŸ³é¢‘æ ¼å¼
            status.update(label="æ­£åœ¨è½¬æ¢éŸ³é¢‘æ ¼å¼ (ffmpeg)...", state="running")
            wav_file = convert_to_wav(audio_file)
            st.write(f"âœ… æ ¼å¼è½¬æ¢å®Œæˆ: {os.path.basename(wav_file)}")

            # æ­¥éª¤3: åŠ è½½æ¨¡å‹
            status.update(label="æ­£åœ¨åŠ è½½ FunASR æ¨¡å‹...", state="running")
            
            st.write(f"âš™ï¸ æ£€æµ‹åˆ°è®¡ç®—è®¾å¤‡: {device_select}")
            st.write("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

            # æ­¥éª¤4: æ‰§è¡Œè¯­éŸ³è¯†åˆ«
            status.update(label="æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ« (Inference)...", state="running")
            
            # FunASR çš„ generate å†…éƒ¨é€šå¸¸ä¼šæœ‰è¿›åº¦æ¡æ‰“å°ï¼Œè¿™é‡Œä¼šè¢«æ•è·
            res = model_instance.generate(input=wav_file, return_sentence_timestamp=True)
            st.session_state.raw_res = res 
            st.write("âœ… è¯†åˆ«æ¨ç†ç»“æŸ")

            # ä¿å­˜ç»“æœ
            st.session_state.transcription_result = res[0]['text']
            try:
                st.session_state.srt_result = generate_smart_srt(res)
                st.write("âœ… SRT å­—å¹•ç”Ÿæˆå®Œæˆ")
            except Exception as e:
                st.write(f"âš ï¸ SRTç”Ÿæˆè­¦å‘Š: {e}")
                st.session_state.srt_result = ""
            st.session_state.is_processed = True

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                st.write("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                os.remove(audio_file)
                os.remove(wav_file)
            except Exception as e:
                st.write(f"âš ï¸ æ¸…ç†æ–‡ä»¶è­¦å‘Š: {e}")

            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            status.update(label="ğŸ‰ å¤„ç†å…¨éƒ¨å®Œæˆï¼", state="complete", expanded=False)

        except Exception as e:
            status.update(label="âŒ å¤„ç†å¤±è´¥", state="error")
            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
            # è¿™é‡Œçš„ print ä¹Ÿä¼šæ˜¾ç¤ºåœ¨æ—¥å¿—æ¡†é‡Œæ–¹ä¾¿è°ƒè¯•
            print(f"Error Details: {e}")
            
        finally:
            # --- å…³é”®ï¼šåŠ¡å¿…æ¢å¤ stdoutï¼Œå¦åˆ™åç»­ Streamlit å¯èƒ½æŠ¥é”™ ---
            sys.stdout = logger.original_stdout

# ç»“æœå±•ç¤ºåŒº (é«˜éš¾åº¦åŠ¨æ€åˆ‡æ¢ç‰ˆ)
if st.session_state.is_processed:
    st.divider()
    
    # 1. é¡¶éƒ¨æ§åˆ¶æ 
    col_ctrl_1, col_ctrl_2 = st.columns([1, 3])
    with col_ctrl_1:
        st.subheader("è¯†åˆ«ç»“æœ")
    with col_ctrl_2:
        # ä½¿ç”¨ toggle å¼€å…³ï¼Œé»˜è®¤å…³é—­(çº¯æ–‡æœ¬æ¨¡å¼)
        is_srt_mode = st.toggle("å¼€å¯ SRT å­—å¹•æ¨¡å¼", value=False)

    # 2. åŠ¨æ€é€»è¾‘å¤„ç†
    if is_srt_mode:
        # --- SRT æ¨¡å¼ ---
        # åˆ›å»ºä¸€ä¸ªæ›´ç»†è‡´çš„è®¾ç½®æ 
        with st.container():
            col_set_1, col_set_2 = st.columns([2, 1])
            with col_set_1:
                st.info("ğŸ’¡ æ™ºèƒ½æ–­å¥ï¼šé€—å·ä¼šå°è¯•åˆå¹¶ï¼Œç›´åˆ°è¾¾åˆ°æœ€å°å­—æ•°ï¼›å¥å·å¼ºåˆ¶æ¢è¡Œã€‚")
            with col_set_2:
                # æ»‘åŠ¨æ¡ï¼šæ§åˆ¶æ–­å¥é˜ˆå€¼
                # key="srt_min_len" ä¼šè‡ªåŠ¨è®°å½•çŠ¶æ€
                min_len = st.slider(
                    "â±ï¸ æœ€å°å­—å¹•å­—æ•° (é€—å·åˆå¹¶é˜ˆå€¼)", 
                    min_value=8, 
                    max_value=80, 
                    value=15, 
                    step=1,
                    key="srt_min_len_slider", # å¿…é¡»ç»™ä¸ªç‹¬ç«‹çš„ key
                    on_change=update_srt_by_slider # ç»‘å®šå›è°ƒå‡½æ•°
                )
        
        
        # ç¬¬ä¸€æ¬¡è¿›å…¥ SRT æ¨¡å¼æ—¶çš„åˆå§‹åŒ–é€»è¾‘
        if "editor_srt" not in st.session_state:
             # å¦‚æœè¿˜æ²¡ç”Ÿæˆè¿‡ï¼Œå…ˆç”Ÿæˆä¸€æ¬¡é»˜è®¤çš„
             if "raw_res" in st.session_state:
                 st.session_state.editor_srt = generate_smart_srt(st.session_state.raw_res, min_length=15)
             else:
                 st.session_state.editor_srt = ""
        # current_content = st.session_state.editor_srt
        current_label = f"ğŸ¬ SRT å­—å¹• (æ¯è¡Œè‡³å°‘ {min_len} å­—)"
        current_filename = "subtitle.srt"
        widget_key = "editor_srt" 
    else:
        # --- çº¯æ–‡æœ¬æ¨¡å¼ ---
        if "editor_txt" not in st.session_state:
            st.session_state.editor_txt = st.session_state.transcription_result
        # current_content = st.session_state.transcription_result
        current_label = "ğŸ“„ çº¯æ–‡æœ¬ç¼–è¾‘"
        current_filename = "transcription.txt"
        widget_key = "editor_txt"

    # 3. ç»Ÿä¸€çš„ç¼–è¾‘åŒºåŸŸ
    # æ³¨æ„ï¼šæˆ‘ä»¬å°† session_state çš„å€¼èµ‹ç»™ value ä½œä¸ºåˆå§‹å€¼
    # ç”¨æˆ·çš„ä¿®æ”¹ä¼šè‡ªåŠ¨æ›´æ–°åˆ° st.session_state[widget_key] ä¸­
    edited_content = st.text_area(
        label=current_label,
        height=600,
        key=widget_key 
    )

    # 4. æ•°æ®åŒæ­¥å›å†™ (è¿™ä¸€æ­¥å¾ˆé‡è¦)
    # å½“ç”¨æˆ·ç¼–è¾‘æ—¶ï¼ŒStreamlit è‡ªåŠ¨æ›´æ–°äº† session_state[widget_key]
    # ä½†æˆ‘ä»¬éœ€è¦æŠŠå®ƒåŒæ­¥å›æˆ‘ä»¬è‡ªå®šä¹‰çš„ result å˜é‡ï¼Œä»¥é˜²ä¸‹æ¬¡åˆ‡æ¢æ—¶æ•°æ®ä¸¢å¤±
    if is_srt_mode:
        st.session_state.srt_result = edited_content
    else:
        st.session_state.transcription_result = edited_content

    # 5. åº•éƒ¨æ“ä½œæ 
    col_act_1, col_act_2 = st.columns([3, 1])
    
    with col_act_1:
        # æ˜¾ç¤ºå½“å‰æ¨¡å¼çš„çŠ¶æ€æç¤º
        if is_srt_mode:
            st.caption("â„¹ï¸ å½“å‰ä¸ºå­—å¹•æ¨¡å¼ï¼Œç¼–è¾‘å†…å®¹å°†ä¿å­˜ä¸º .srt æ ¼å¼")
        else:
            st.caption("â„¹ï¸ å½“å‰ä¸ºçº¯æ–‡æœ¬æ¨¡å¼ï¼Œç¼–è¾‘å†…å®¹å°†ä¿å­˜ä¸º .txt æ ¼å¼")
            
    with col_act_2:
        # ä¸‹è½½æŒ‰é’®ä¹Ÿæ˜¯åŠ¨æ€çš„
        st.download_button(
            label=f"ğŸ“¥ å¯¼å‡º {current_filename}",
            data=edited_content,
            file_name=current_filename,
            mime="text/plain",
            type="primary", # é†’ç›®æ ·å¼
            use_container_width=True
        )
