import streamlit as st
import tempfile
import os
import sys
import torch
import time
from audio_downloader import download_audio
from audio_converter import convert_to_wav
from funasr import AutoModel

# --- æ ¸å¿ƒç»„ä»¶ï¼šæ—¥å¿—é‡å®šå‘ç±» ---
class StreamlitLogger:
    """
    è¿™ä¸ªç±»ç”¨äºæ•è· print è¾“å‡ºå¹¶å®æ—¶æ˜¾ç¤ºåœ¨ Streamlit çš„ä»£ç æ¡†ä¸­
    """
    def __init__(self, log_container):
        self.log_container = log_container
        self.log_buffer = []
        # ä¿å­˜åŸå§‹çš„ stdout ä»¥ä¾¿æ¢å¤
        self.original_stdout = sys.stdout

    def write(self, message):
        # å®æ—¶æ‰“å°åˆ°ç»ˆç«¯ï¼ˆä¿ç•™åŸå§‹è¡Œä¸ºï¼‰
        self.original_stdout.write(message)
        
        # è¿‡æ»¤æ‰ç©ºçš„æ¢è¡Œï¼Œé¿å…åˆ·å±å¤ªå¿«è§†è§‰æ•ˆæœä¸å¥½
        if message.strip():
            self.log_buffer.append(message)
            # ä¸ºäº†æ€§èƒ½ï¼Œåªæ˜¾ç¤ºæœ€å 20 è¡Œæ—¥å¿—
            display_text = "".join(self.log_buffer[-20:])
            # å®æ—¶æ›´æ–° Streamlit å®¹å™¨
            self.log_container.code(display_text, language="bash")

    def flush(self):
        self.original_stdout.flush()

# --- ä¸»ç¨‹åº ---

# åˆå§‹åŒ–session state
if "transcription_result" not in st.session_state:
    st.session_state.transcription_result = ""

if "is_processed" not in st.session_state:
    st.session_state.is_processed = False

st.set_page_config(page_title="Video2Text", page_icon="ğŸ§")
st.title("ğŸ§ Video2Text - è¯­éŸ³è¯†åˆ«å·¥å…·")
st.markdown("å°†YouTube/Bilibiliè§†é¢‘è½¬æ¢ä¸ºæ–‡å­—")

# è§†é¢‘é“¾æ¥è¾“å…¥
video_url = st.text_input("è¯·è¾“å…¥YouTubeæˆ–Bilibiliè§†é¢‘é“¾æ¥:", placeholder="https://www.youtube.com/watch?v=...")

# å¤„ç†æŒ‰é’®
if st.button("å¼€å§‹å¤„ç†", type="primary") and video_url:
    st.session_state.is_processed = False
    
    # 1. åˆ›å»ºä¸€ä¸ªæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸï¼ˆé»˜è®¤æŠ˜å ï¼‰
    with st.expander("æŸ¥çœ‹è¯¦ç»†è¿è¡Œæ—¥å¿— (Terminal Output)", expanded=True):
        log_placeholder = st.empty()
    
    # å®ä¾‹åŒ–æˆ‘ä»¬çš„æ—¥å¿—æ•è·å™¨
    logger = StreamlitLogger(log_placeholder)
    
    # 2. ä½¿ç”¨ st.status åˆ›å»ºæ¼‚äº®çš„è¿›åº¦å®¹å™¨
    with st.status("æ­£åœ¨åˆå§‹åŒ–ä»»åŠ¡...", expanded=True) as status:
        
        # --- å…³é”®ï¼šå¼€å§‹åŠ«æŒ stdout ---
        sys.stdout = logger 
        sys.stderr = logger
        
        try:
            # æ­¥éª¤1: ä¸‹è½½éŸ³é¢‘
            status.update(label="æ­£åœ¨ä¸‹è½½éŸ³é¢‘ (yt-dlp)...", state="running")
            st.write("ğŸš€ å¼€å§‹è°ƒç”¨ä¸‹è½½å·¥å…·...") # è¿™è¡Œå­—ä¼šæ˜¾ç¤ºåœ¨æ—¥å¿—æ¡†é‡Œ
            
            # æ³¨æ„ï¼šå¦‚æœ download_audio å†…éƒ¨ä½¿ç”¨äº† printï¼Œä¼šè¢«æ•è·ã€‚
            # å¦‚æœå®ƒä½¿ç”¨ subprocess ç›´æ¥è¾“å‡ºåˆ°ç³»ç»Ÿç»ˆç«¯ï¼Œå¯èƒ½æ— æ³•è¢«æ•è·ï¼ˆè§ä¸‹æ–¹è¯´æ˜ï¼‰ã€‚
            audio_file = download_audio(video_url)
            st.write(f"âœ… ä¸‹è½½å®Œæˆ: {os.path.basename(audio_file)}")
            
            # æ­¥éª¤2: è½¬æ¢éŸ³é¢‘æ ¼å¼
            status.update(label="æ­£åœ¨è½¬æ¢éŸ³é¢‘æ ¼å¼ (ffmpeg)...", state="running")
            wav_file = convert_to_wav(audio_file)
            st.write(f"âœ… æ ¼å¼è½¬æ¢å®Œæˆ: {os.path.basename(wav_file)}")

            # æ­¥éª¤3: åŠ è½½æ¨¡å‹
            status.update(label="æ­£åœ¨åŠ è½½ FunASR æ¨¡å‹...", state="running")
            
            if torch.cuda.is_available():
                device_select = "cuda"
            elif torch.backends.mps.is_available():
                device_select = "mps"
            else:
                device_select = "cpu"
                
            st.write(f"âš™ï¸ æ£€æµ‹åˆ°è®¡ç®—è®¾å¤‡: {device_select}")
            
            model = AutoModel(model="paraformer-zh", model_revision="v2.0.4",
                    vad_model="fsmn-vad", vad_model_revision="v2.0.4",
                    punc_model="ct-punc-c", punc_model_revision="v2.0.4",
                    device=device_select,
                    # æ³¨æ„ï¼šè®¾ä¸º0æˆ–1ï¼Œå¤šè¿›ç¨‹å¯èƒ½å¯¼è‡´ print æ•è·ä¸åˆ°
                    num_workers=0, 
                    )
            st.write("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

            # æ­¥éª¤4: æ‰§è¡Œè¯­éŸ³è¯†åˆ«
            status.update(label="æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ« (Inference)...", state="running")
            
            # FunASR çš„ generate å†…éƒ¨é€šå¸¸ä¼šæœ‰è¿›åº¦æ¡æ‰“å°ï¼Œè¿™é‡Œä¼šè¢«æ•è·
            res = model.generate(input=wav_file)
            st.write("âœ… è¯†åˆ«æ¨ç†ç»“æŸ")

            # ä¿å­˜ç»“æœ
            st.session_state.transcription_result = res[0]['text']
            st.session_state.is_processed = True

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                st.write("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                os.remove(audio_file)
                os.remove(wav_file)
            except Exception as e:
                st.write(f"âš ï¸ æ¸…ç†æ–‡ä»¶è­¦å‘Š: {e}")

            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            status.update(label="ğŸ‰ å¤„ç†å…¨éƒ¨å®Œæˆï¼", state="complete", expanded=False)

        except Exception as e:
            status.update(label="âŒ å¤„ç†å¤±è´¥", state="error")
            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
            # è¿™é‡Œçš„ print ä¹Ÿä¼šæ˜¾ç¤ºåœ¨æ—¥å¿—æ¡†é‡Œæ–¹ä¾¿è°ƒè¯•
            print(f"Error Details: {e}")
            
        finally:
            # --- å…³é”®ï¼šåŠ¡å¿…æ¢å¤ stdoutï¼Œå¦åˆ™åç»­ Streamlit å¯èƒ½æŠ¥é”™ ---
            sys.stdout = logger.original_stdout

# ç»“æœå±•ç¤ºå’Œç¼–è¾‘åŒºåŸŸ
if st.session_state.is_processed:
    st.divider()
    st.subheader("ğŸ“ è½¬å½•ç»“æœ")
    
    col_l, col_r = st.columns([3, 1])
    
    with col_l:
        edited_text = st.text_area("ç¼–è¾‘æ–‡æœ¬", value=st.session_state.transcription_result, height=400, label_visibility="collapsed")
        st.session_state.transcription_result = edited_text

    with col_r:
        st.info("æ“ä½œæ ")
        if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", use_container_width=True):
            st.toast("æ–‡æœ¬å·²ä¿å­˜åˆ°å†…å­˜ï¼")
            
        st.download_button(
            label="ğŸ“¥ å¯¼å‡º TXT",
            data=st.session_state.transcription_result,
            file_name="transcription.txt",
            mime="text/plain",
            use_container_width=True
        )